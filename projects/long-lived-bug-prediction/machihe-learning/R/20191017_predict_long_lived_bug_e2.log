nohup: ignoring input
Loading required package: caret
Loading required package: lattice
Loading required package: ggplot2
Loading required package: doParallel
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
Loading required package: e1071
Loading required package: klaR
Loading required package: MASS
Loading required package: kernlab

Attaching package: ‘kernlab’

The following object is masked from ‘package:ggplot2’:

    alpha

Loading required package: futile.logger
Loading required package: nnet
Loading required package: qdap
Loading required package: qdapDictionaries
Loading required package: qdapRegex

Attaching package: ‘qdapRegex’

The following object is masked from ‘package:ggplot2’:

    %+%

Loading required package: qdapTools
Loading required package: RColorBrewer
Registered S3 methods overwritten by 'qdap':
  method               from
  t.DocumentTermMatrix tm  
  t.TermDocumentMatrix tm  

Attaching package: ‘qdap’

The following object is masked from ‘package:base’:

    Filter

Loading required package: randomForest
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:ggplot2’:

    margin

Loading required package: SnowballC
Loading required package: smotefamily
Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──
✔ tibble  2.1.3     ✔ purrr   0.3.2
✔ tidyr   1.0.0     ✔ dplyr   0.8.3
✔ readr   1.3.1     ✔ stringr 1.4.0
✔ tibble  2.1.3     ✔ forcats 0.4.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ qdapRegex::%+%()       masks ggplot2::%+%()
✖ purrr::accumulate()    masks foreach::accumulate()
✖ kernlab::alpha()       masks ggplot2::alpha()
✖ dplyr::combine()       masks randomForest::combine()
✖ purrr::cross()         masks kernlab::cross()
✖ dplyr::explain()       masks qdapRegex::explain()
✖ dplyr::filter()        masks stats::filter()
✖ dplyr::id()            masks qdapTools::id()
✖ dplyr::lag()           masks stats::lag()
✖ purrr::lift()          masks caret::lift()
✖ randomForest::margin() masks ggplot2::margin()
✖ dplyr::select()        masks MASS::select()
✖ purrr::when()          masks foreach::when()
Loading required package: tidytext
Loading required package: tm
Loading required package: NLP

Attaching package: ‘NLP’

The following object is masked from ‘package:qdap’:

    ngrams

The following object is masked from ‘package:ggplot2’:

    annotate


Attaching package: ‘tm’

The following objects are masked from ‘package:qdap’:

    as.DocumentTermMatrix, as.TermDocumentMatrix

Loading required package: xgboost

Attaching package: ‘xgboost’

The following object is masked from ‘package:dplyr’:

    slice

NULL
TRACE [2019-10-17 11:59:49] Long live prediction Research Question 3 - Experiment 2
TRACE [2019-10-17 11:59:49] Evaluation metrics ouput path: ~/Workspace/doctorate/projects/long-lived-bug-prediction/notebooks/datasets
TRACE [2019-10-17 11:59:49] Current project name : eclipse
TRACE [2019-10-17 11:59:49] New Evaluation file: ~/Workspace/doctorate/projects/long-lived-bug-prediction/notebooks/datasets/20191017115944_rq3e2_eclipse_predict_long_lived_metrics.csv
TRACE [2019-10-17 11:59:49] Starting in parameter number: 1
TRACE [2019-10-17 11:59:49] Bug report file name: ~/Workspace/doctorate/projects/long-lived-bug-prediction/notebooks/datasets/20190917_eclipse_bug_report_data.csv
TRACE [2019-10-17 11:59:49] Clean text features
TRACE [2019-10-17 12:00:26] Current parameters:
 N.Terms...: [100]
 Classifier: [nn]
 Metric...: [Kappa]
 Feature...: [long_description]
 Threshold.: [365]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-10-17 12:00:26] Converting dataframe to term matrix
TRACE [2019-10-17 12:00:26] Text mining: extracting 100 terms from long_description
TRACE [2019-10-17 12:00:50] Text mining: extracted 100 terms from long_description
TRACE [2019-10-17 12:00:50] Partitioning dataset in training and testing
TRACE [2019-10-17 12:00:50] Balancing training dataset
TRACE [2019-10-17 12:00:50] [balance_dataset]: balancing method: smote
TRACE [2019-10-17 12:00:52] Training model 
TRACE [2019-10-17 12:00:52] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-10-17 12:00:52] [train_with_nnet] Training model with NNET and Kappa
# weights:  2041
initial  value 12469.989886 
iter  10 value 8218.918575
iter  20 value 8076.508407
iter  30 value 8002.241658
iter  40 value 7872.693673
iter  50 value 7708.230306
iter  60 value 7608.580419
iter  70 value 7513.895700
iter  80 value 7417.706024
iter  90 value 7343.113102
iter 100 value 7297.719838
final  value 7297.719838 
stopped after 100 iterations
TRACE [2019-10-17 12:04:42] Testing model 
TRACE [2019-10-17 12:04:42] Calculating evaluating metrics
TRACE [2019-10-17 12:04:43] Evaluating metrics calculated!
TRACE [2019-10-17 12:04:43] Metrics: sensitivity [0.379679], specificity [0.704638], b_acc [0.542158]
TRACE [2019-10-17 12:04:43] Recording evaluation results on CSV file.
TRACE [2019-10-17 12:04:43] Evaluation results recorded on CSV file.
TRACE [2019-10-17 12:04:43] Current parameters:
 N.Terms...: [150]
 Classifier: [nn]
 Metric...: [Kappa]
 Feature...: [long_description]
 Threshold.: [365]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-10-17 12:04:43] Converting dataframe to term matrix
TRACE [2019-10-17 12:04:43] Text mining: extracting 150 terms from long_description
TRACE [2019-10-17 12:05:03] Text mining: extracted 150 terms from long_description
TRACE [2019-10-17 12:05:03] Partitioning dataset in training and testing
TRACE [2019-10-17 12:05:03] Balancing training dataset
TRACE [2019-10-17 12:05:03] [balance_dataset]: balancing method: smote
TRACE [2019-10-17 12:05:07] Training model 
TRACE [2019-10-17 12:05:07] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-10-17 12:05:07] [train_with_nnet] Training model with NNET and Kappa
# weights:  1521
initial  value 9333.530969 
iter  10 value 8166.115530
iter  20 value 7949.016353
iter  30 value 7691.670355
iter  40 value 7484.954812
iter  50 value 7353.445875
iter  60 value 7195.750308
iter  70 value 7036.601851
iter  80 value 6930.591266
iter  90 value 6855.433422
iter 100 value 6808.835171
final  value 6808.835171 
stopped after 100 iterations
TRACE [2019-10-17 12:08:39] Testing model 
TRACE [2019-10-17 12:08:39] Calculating evaluating metrics
TRACE [2019-10-17 12:08:39] Evaluating metrics calculated!
TRACE [2019-10-17 12:08:39] Metrics: sensitivity [0.335106], specificity [0.745634], b_acc [0.540370]
TRACE [2019-10-17 12:08:39] Recording evaluation results on CSV file.
TRACE [2019-10-17 12:08:39] Evaluation results recorded on CSV file.
TRACE [2019-10-17 12:08:39] Current parameters:
 N.Terms...: [200]
 Classifier: [nn]
 Metric...: [Kappa]
 Feature...: [long_description]
 Threshold.: [365]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-10-17 12:08:39] Converting dataframe to term matrix
TRACE [2019-10-17 12:08:39] Text mining: extracting 200 terms from long_description
TRACE [2019-10-17 12:09:00] Text mining: extracted 200 terms from long_description
TRACE [2019-10-17 12:09:00] Partitioning dataset in training and testing
TRACE [2019-10-17 12:09:00] Balancing training dataset
TRACE [2019-10-17 12:09:00] [balance_dataset]: balancing method: smote
TRACE [2019-10-17 12:09:04] Training model 
TRACE [2019-10-17 12:09:04] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-10-17 12:09:04] [train_with_nnet] Training model with NNET and Kappa
# weights:  4041
initial  value 9305.227470 
iter  10 value 8121.230396
iter  20 value 7732.218863
iter  30 value 7494.650041
iter  40 value 7242.637987
iter  50 value 7022.995896
iter  60 value 6863.821350
iter  70 value 6724.198224
iter  80 value 6604.924655
iter  90 value 6483.244915
iter 100 value 6392.538950
final  value 6392.538950 
stopped after 100 iterations
TRACE [2019-10-17 12:12:16] Testing model 
TRACE [2019-10-17 12:12:16] Calculating evaluating metrics
TRACE [2019-10-17 12:12:16] Evaluating metrics calculated!
TRACE [2019-10-17 12:12:16] Metrics: sensitivity [0.260638], specificity [0.787757], b_acc [0.524198]
TRACE [2019-10-17 12:12:16] Recording evaluation results on CSV file.
TRACE [2019-10-17 12:12:16] Evaluation results recorded on CSV file.
TRACE [2019-10-17 12:12:16] Current parameters:
 N.Terms...: [250]
 Classifier: [nn]
 Metric...: [Kappa]
 Feature...: [long_description]
 Threshold.: [365]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-10-17 12:12:16] Converting dataframe to term matrix
TRACE [2019-10-17 12:12:16] Text mining: extracting 250 terms from long_description
TRACE [2019-10-17 12:12:36] Text mining: extracted 250 terms from long_description
TRACE [2019-10-17 12:12:36] Partitioning dataset in training and testing
TRACE [2019-10-17 12:12:36] Balancing training dataset
TRACE [2019-10-17 12:12:36] [balance_dataset]: balancing method: smote
TRACE [2019-10-17 12:12:42] Training model 
TRACE [2019-10-17 12:12:42] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-10-17 12:12:42] [train_with_nnet] Training model with NNET and Kappa
# weights:  2521
initial  value 10630.363014 
iter  10 value 8516.125756
iter  20 value 7766.005933
iter  30 value 7390.296801
iter  40 value 6867.795282
iter  50 value 6561.930651
iter  60 value 6353.121826
iter  70 value 6219.326445
iter  80 value 6120.132474
iter  90 value 6005.337187
iter 100 value 5953.313389
final  value 5953.313389 
stopped after 100 iterations
TRACE [2019-10-17 12:14:16] Testing model 
TRACE [2019-10-17 12:14:16] Calculating evaluating metrics
TRACE [2019-10-17 12:14:16] Evaluating metrics calculated!
TRACE [2019-10-17 12:14:16] Metrics: sensitivity [0.234043], specificity [0.804105], b_acc [0.519074]
TRACE [2019-10-17 12:14:16] Recording evaluation results on CSV file.
TRACE [2019-10-17 12:14:16] Evaluation results recorded on CSV file.
TRACE [2019-10-17 12:14:16] Current parameters:
 N.Terms...: [300]
 Classifier: [nn]
 Metric...: [Kappa]
 Feature...: [long_description]
 Threshold.: [365]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-10-17 12:14:16] Converting dataframe to term matrix
TRACE [2019-10-17 12:14:16] Text mining: extracting 300 terms from long_description
TRACE [2019-10-17 12:14:36] Text mining: extracted 300 terms from long_description
TRACE [2019-10-17 12:14:36] Partitioning dataset in training and testing
TRACE [2019-10-17 12:14:36] Balancing training dataset
TRACE [2019-10-17 12:14:36] [balance_dataset]: balancing method: smote
TRACE [2019-10-17 12:14:42] Training model 
TRACE [2019-10-17 12:14:42] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-10-17 12:14:42] [train_with_nnet] Training model with NNET and Kappa
# weights:  3021
initial  value 9498.588213 
iter  10 value 7841.942726
iter  20 value 7307.232857
iter  30 value 7057.126595
iter  40 value 6740.644456
iter  50 value 6452.722813
iter  60 value 6228.558991
iter  70 value 6056.402832
iter  80 value 5865.054133
iter  90 value 5753.342888
iter 100 value 5690.082913
final  value 5690.082913 
stopped after 100 iterations
TRACE [2019-10-17 12:16:39] Testing model 
TRACE [2019-10-17 12:16:39] Calculating evaluating metrics
TRACE [2019-10-17 12:16:39] Evaluating metrics calculated!
TRACE [2019-10-17 12:16:39] Metrics: sensitivity [0.238095], specificity [0.816763], b_acc [0.527429]
TRACE [2019-10-17 12:16:39] Recording evaluation results on CSV file.
TRACE [2019-10-17 12:16:39] Evaluation results recorded on CSV file.
There were 15 warnings (use warnings() to see them)
