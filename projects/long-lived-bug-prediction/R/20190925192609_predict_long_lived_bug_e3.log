nohup: ignoring input
Loading required package: caret
Loading required package: lattice
Loading required package: ggplot2
Loading required package: doParallel
Loading required package: foreach
Loading required package: iterators
Loading required package: parallel
Loading required package: e1071
Loading required package: klaR
Loading required package: MASS
Loading required package: kernlab

Attaching package: ‘kernlab’

The following object is masked from ‘package:ggplot2’:

    alpha

Loading required package: futile.logger
Loading required package: nnet
Loading required package: qdap
Loading required package: qdapDictionaries
Loading required package: qdapRegex

Attaching package: ‘qdapRegex’

The following object is masked from ‘package:ggplot2’:

    %+%

Loading required package: qdapTools
Loading required package: RColorBrewer
Registered S3 methods overwritten by 'qdap':
  method               from
  t.DocumentTermMatrix tm  
  t.TermDocumentMatrix tm  

Attaching package: ‘qdap’

The following object is masked from ‘package:base’:

    Filter

Loading required package: randomForest
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:ggplot2’:

    margin

Loading required package: SnowballC
Loading required package: smotefamily
Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──
✔ tibble  2.1.3     ✔ purrr   0.3.2
✔ tidyr   1.0.0     ✔ dplyr   0.8.3
✔ readr   1.3.1     ✔ stringr 1.4.0
✔ tibble  2.1.3     ✔ forcats 0.4.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ qdapRegex::%+%()       masks ggplot2::%+%()
✖ purrr::accumulate()    masks foreach::accumulate()
✖ kernlab::alpha()       masks ggplot2::alpha()
✖ dplyr::combine()       masks randomForest::combine()
✖ purrr::cross()         masks kernlab::cross()
✖ dplyr::explain()       masks qdapRegex::explain()
✖ dplyr::filter()        masks stats::filter()
✖ dplyr::id()            masks qdapTools::id()
✖ dplyr::lag()           masks stats::lag()
✖ purrr::lift()          masks caret::lift()
✖ randomForest::margin() masks ggplot2::margin()
✖ dplyr::select()        masks MASS::select()
✖ purrr::when()          masks foreach::when()
Loading required package: tidytext
Loading required package: tm
Loading required package: NLP

Attaching package: ‘NLP’

The following object is masked from ‘package:qdap’:

    ngrams

The following object is masked from ‘package:ggplot2’:

    annotate


Attaching package: ‘tm’

The following objects are masked from ‘package:qdap’:

    as.DocumentTermMatrix, as.TermDocumentMatrix

Loading required package: xgboost

Attaching package: ‘xgboost’

The following object is masked from ‘package:dplyr’:

    slice

NULL
TRACE [2019-09-25 20:08:41] Long live prediction Research Question 3 - Experiment 3
TRACE [2019-09-25 20:08:41] Evaluation metrics ouput path: ~/Workspace/doctorate/long-lived-bug-prediction/notebooks/datasets
TRACE [2019-09-25 20:08:41] Current project name : eclipse
TRACE [2019-09-25 20:08:41] New Evaluation file: ~/Workspace/doctorate/long-lived-bug-prediction/notebooks/datasets/20190925200836_rq3e3_eclipse_predict_long_lived_metrics.csv
TRACE [2019-09-25 20:08:41] Starting in parameter number: 1
TRACE [2019-09-25 20:08:41] Bug report file name: ~/Workspace/doctorate/long-lived-bug-prediction/notebooks/datasets/20190917_eclipse_bug_report_data.csv
TRACE [2019-09-25 20:08:41] Clean text features
TRACE [2019-09-25 20:09:13] Current parameters:
 N.Terms...: [100]
 Classifier: [nn]
 Metric...: [Accuracy]
 Feature...: [long_description]
 Threshold.: [1]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-09-25 20:09:13] Converting dataframe to term matrix
TRACE [2019-09-25 20:09:13] Text mining: extracting 100 terms from long_description
TRACE [2019-09-25 20:09:34] Text mining: extracted 100 terms from long_description
TRACE [2019-09-25 20:09:34] Partitioning dataset in training and testing
TRACE [2019-09-25 20:09:34] Balancing training dataset
TRACE [2019-09-25 20:09:34] [balance_dataset]: balancing method: smote
TRACE [2019-09-25 20:09:40] Training model 
TRACE [2019-09-25 20:09:40] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-09-25 20:09:40] [train_with_nnet] Training model with NNET and Accuracy
# weights:  2041
initial  value 8425.728414 
iter  10 value 6397.260339
iter  20 value 6331.737659
iter  30 value 6321.420335
iter  40 value 6316.773437
iter  50 value 6314.175789
iter  60 value 6312.802666
iter  70 value 6312.352047
iter  80 value 6312.137700
iter  90 value 6311.953442
iter 100 value 6311.814071
final  value 6311.814071 
stopped after 100 iterations
TRACE [2019-09-25 20:12:28] Testing model 
TRACE [2019-09-25 20:12:28] Calculating evaluating metrics
TRACE [2019-09-25 20:12:28] Evaluating metrics calculated!
TRACE [2019-09-25 20:12:28] Metrics: sensitivity [0.702494], specificity [0.393646], b_acc [0.548070]
TRACE [2019-09-25 20:12:28] Recording evaluation results on CSV file.
TRACE [2019-09-25 20:12:28] Evaluation results recorded on CSV file.
TRACE [2019-09-25 20:12:28] Current parameters:
 N.Terms...: [100]
 Classifier: [nn]
 Metric...: [Accuracy]
 Feature...: [long_description]
 Threshold.: [8]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-09-25 20:12:28] Partitioning dataset in training and testing
TRACE [2019-09-25 20:12:28] Balancing training dataset
TRACE [2019-09-25 20:12:28] [balance_dataset]: balancing method: smote
TRACE [2019-09-25 20:12:34] Training model 
TRACE [2019-09-25 20:12:34] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-09-25 20:12:34] [train_with_nnet] Training model with NNET and Accuracy
# weights:  4081
initial  value 5895.563229 
iter  10 value 4987.336250
iter  20 value 4922.840871
iter  30 value 4913.333809
iter  40 value 4912.220313
iter  50 value 4911.768628
iter  60 value 4911.133465
iter  70 value 4910.746599
iter  80 value 4910.481682
iter  90 value 4910.344749
iter 100 value 4910.262245
final  value 4910.262245 
stopped after 100 iterations
TRACE [2019-09-25 20:15:17] Testing model 
TRACE [2019-09-25 20:15:17] Calculating evaluating metrics
TRACE [2019-09-25 20:15:17] Evaluating metrics calculated!
TRACE [2019-09-25 20:15:17] Metrics: sensitivity [0.546058], specificity [0.506234], b_acc [0.526146]
TRACE [2019-09-25 20:15:17] Recording evaluation results on CSV file.
TRACE [2019-09-25 20:15:17] Evaluation results recorded on CSV file.
TRACE [2019-09-25 20:15:17] Current parameters:
 N.Terms...: [100]
 Classifier: [nn]
 Metric...: [Accuracy]
 Feature...: [long_description]
 Threshold.: [63]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-09-25 20:15:17] Partitioning dataset in training and testing
TRACE [2019-09-25 20:15:17] Balancing training dataset
TRACE [2019-09-25 20:15:17] [balance_dataset]: balancing method: smote
TRACE [2019-09-25 20:15:21] Training model 
TRACE [2019-09-25 20:15:21] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-09-25 20:15:21] [train_with_nnet] Training model with NNET and Accuracy
# weights:  2041
initial  value 9866.335387 
iter  10 value 5954.529140
iter  20 value 5881.405505
iter  30 value 5873.012217
iter  40 value 5871.370305
iter  50 value 5870.821728
iter  60 value 5870.504385
iter  70 value 5870.428380
iter  80 value 5870.400294
iter  90 value 5870.346551
iter 100 value 5870.241852
final  value 5870.241852 
stopped after 100 iterations
TRACE [2019-09-25 20:18:06] Testing model 
TRACE [2019-09-25 20:18:06] Calculating evaluating metrics
TRACE [2019-09-25 20:18:06] Evaluating metrics calculated!
TRACE [2019-09-25 20:18:06] Metrics: sensitivity [0.170813], specificity [0.850970], b_acc [0.510891]
TRACE [2019-09-25 20:18:06] Recording evaluation results on CSV file.
TRACE [2019-09-25 20:18:06] Evaluation results recorded on CSV file.
TRACE [2019-09-25 20:18:06] Current parameters:
 N.Terms...: [100]
 Classifier: [nn]
 Metric...: [Accuracy]
 Feature...: [long_description]
 Threshold.: [365]
 Balancing.: [smote]
 Resampling: [repeatedcv]
TRACE [2019-09-25 20:18:06] Partitioning dataset in training and testing
TRACE [2019-09-25 20:18:06] Balancing training dataset
TRACE [2019-09-25 20:18:06] [balance_dataset]: balancing method: smote
TRACE [2019-09-25 20:18:08] Training model 
TRACE [2019-09-25 20:18:08] [get_resampling_method] Resampling model repeatedcv
TRACE [2019-09-25 20:18:08] [train_with_nnet] Training model with NNET and Accuracy
# weights:  2041
initial  value 12469.989886 
iter  10 value 8218.918575
iter  20 value 8076.508407
iter  30 value 8002.241658
iter  40 value 7872.693673
iter  50 value 7708.230306
iter  60 value 7608.580419
iter  70 value 7513.895700
iter  80 value 7417.706024
iter  90 value 7343.113102
iter 100 value 7297.719838
final  value 7297.719838 
stopped after 100 iterations
TRACE [2019-09-25 20:21:59] Testing model 
TRACE [2019-09-25 20:21:59] Calculating evaluating metrics
TRACE [2019-09-25 20:21:59] Evaluating metrics calculated!
TRACE [2019-09-25 20:21:59] Metrics: sensitivity [0.379679], specificity [0.704638], b_acc [0.542158]
TRACE [2019-09-25 20:21:59] Recording evaluation results on CSV file.
TRACE [2019-09-25 20:21:59] Evaluation results recorded on CSV file.
There were 50 or more warnings (use warnings() to see the first 50)
