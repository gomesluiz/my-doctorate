
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

\documentclass[10pt, conference]{IEEEtran}

\usepackage{booktabs}
\usepackage{cite}
\usepackage{color}
\usepackage{enumerate}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{multicol}
\usepackage{multirow}

%\usepackage[brazil]{babel}
%\usepackage[cmex10]{amsmath}
%\usepackage{algorithmic}
%\usepackage{array}
%\usepackage{mdwmath}
%\usepackage{mdwtab}
%\usepackage{eqparbox}
%\usepackage[tight,footnotesize]{subfigure}
%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
%\usepackage[caption=false,font=footnotesize]{subfig}
%\usepackage{fixltx2e}
%\usepackage{stfloats}
\usepackage{url}


\newif\ifComments

% To turn comments OFF simply comment out the \Commentstrue line
%\Commentstrue

\ifComments
\newcommand{\luiz}[1]{\noindent\textcolor{cyan}{LUIZ: {#1}}}
\newcommand{\mario}[1]{\noindent\textcolor{cyan}{MARIO: {#1}}}
\newcommand{\rem}[1]{\noindent\textcolor{magenta}{REMOVED: {#1}}}
\newcommand{\new}[1]{\noindent\textcolor{blue}{NEW: {#1}}}
\newcommand{\rev}[1]{\noindent\textcolor{red}{REVISE: {#1}}}
\else
\newcommand{\luiz}[1]{}
\newcommand{\mario}[1]{}
\newcommand{\rem}[1]{}
\newcommand{\new}[1]{#1}
\newcommand{\rev}[1]{#1}
\fi

% correct bad hyphenation here
\hyphenation{}
\usetikzlibrary{shapes.geometric, arrows}

\tikzstyle{activity} = [rectangle, rounded corners, minimum width=5cm, minimum 
height=1cm,text centered, draw=black, fill=white]
\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]
\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=1cm, text centered, text width=3cm, draw=black, fill=orange!30]
\tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]
\tikzstyle{line} = [draw, -latex']


\begin{document}

\title{Machine Learning Based Prediction of Change Request Severity Level: Experimental Results}

\author{\IEEEauthorblockN{Luiz Alberto Ferreira Gomes}
\IEEEauthorblockA{Software Engineering Departament\\
Pontifical Catholic University of Minas Gerais - PUC MG\\
Poços de Caldas, Brazil\\
luizgomes@pucpcaldas.br}
\and
\IEEEauthorblockN{Mario Lúcio Côrtes}
\IEEEauthorblockA{Institute of Computing\\
State University of Campinas - UNICAMP\\
Campinas, Brasil\\
cortes@ic.unicamp.br}
}
\maketitle

\begin{abstract}
\rem{In the context de Change Request (CR) systems, the severity level of a change request is considered a critical variable in the planning of the software maintenance activities, indicating as soon a CR needs to be fixed. However, the severity level assignment remains a process primarily manual depending on the experience and expertise who has reported the CR. In this paper, we present the preliminary findings of research aim to predict the severity level of a CR by analyzing its long description using text mining and a classifier based on Random Forest algorithm. The results have evidenced that this classifier can predict the severity level will change and whether severity will increase or decrease with reasonable accuracy, around 93.681\% and 93.86\% respectively. However, it has provided poor accuracy (around 67,29\%) to predict the final last severity level in imbalanced data scenario.} \new{In the context of Change Request (CR) systems, the severity level of a change request is considered a critical variable when planning software maintenance activities, indicating how soon a CR needs to be \rem{alternatives: treated, addressed, implemented, carried out, scheduled} \luiz{addressed}\new{addressed}. However, the severity level assignment remains primarily a manual process, mostly depending on the experience and expertise of the person who has reported the CR. In this paper, we present preliminary findings of \new{ongoing} research aimed to predict the severity level of a CR by analyzing its long description, using text mining techniques and Machine Learning (ML) algorithms. \rem{The best}\new{Best} results were obtained with a classifier based on the Random Forest ML algorithm. This classifier can predict whether the severity level will change (accuracy of 93.681\%) and if it will increase or decrease (accuracy of 93.440\%). However, preliminary results were not as good when predicting the final severity level in an imbalanced data scenario.} 

\end{abstract}

\begin{IEEEkeywords}
software maintenance; change request systems; machine learning; random forest.
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
Change Request (CR) systems \rem{has been performed a critical} \new{have played a major} role in maintenance process in many software development settings, both in Close Source Software (CSS) and in Open Source Software (OSS) scenarios. Mainly in the latter, which is characterized by the existence of many of users and developers with \rem{distinct expertise levels} \new{different levels of expertise} spread out around the world, who might \rem{register or deal with any amount of} \new{create or be responsible for dealing with several} change requests\cite{Cavalcanti2014}. 

A user interacts with a CR system often through a simple mechanism called CR form. This form enables him to request changes, to report bugs or to ask for support in a software product\cite{Sommerville2010}. Initially, he or she should inform a short description, a long description, a type (e.g. bug, new feature, improvement, and task) and an associated severity level (e.g. blocker, critical, major, minor and trivial)\rem{ for his or her solicitation} \mario{evite a palavra solicitation}. Subsequently, a development team member will review this request and, case it is not refused for some reason (e.g. request duplication), he or she will complete the information in CR form, indicating, for example, its priority and the person responsible for accomplishing it. \mario{importante usar terminologia e jargao do ramo: acho que aqui nao eh accomplish e sim assigned for the CR; verificar em outros artigos}

The severity level information is recognized as a critical variable in the equation to estimate a prioritization of change request \rem{prioritization}\cite{Tian2012} \mario{repetido}. Consequently, it can be a decisive factor how soon it needs to be fixed\cite{Lamkanfi2010}. However, the severity level assignment remains a mostly manual process which relies on experience and expertise of the person who has opened the CR \cite{Cavalcanti2014, Tian2012, Lamkanfi2010}. So, it may allow a high degree of subjectivity and, consequently, it may be quite error-prone. 

The number of CR made is frequently very high in large and medium software OSS projects\cite{Lamkanfi2011}. Severity level shifts throughout CR lifecycle (Figure \ref{fig:cr-life-cycle}) could cause relevants impacts on the maintenance activities planning and could drive the development team to solve the least significant change requests before the most important ones. 

Machine Learning (ML) techniques have been applied successfully in solving real problems in many areas of knowledge, including those related to CR, such as duplication and assignment of CR\cite{Cavalcanti2014}. However, the accuracy of ML algorithms may be affected by imbalance datasets \cite{Chawla2009} \textemdash a recurring critical problem in CR repositories\cite{Tian2015}. For example, more than 60\% of CRs may have a "major" severity level. 


\begin{figure}[hbt!]  
  \centering
  \begin{tikzpicture}[node distance=1.5cm]
    \node (a1) [activity] {Open};
    \node (a2) [activity, below of=a1] {In Progress};
    \node (a3) [activity, below of=a2] {Resolved};
    \node (a4) [activity, below of=a3] {Closed};
    \node (a5) [activity, below of=a4] {Reopened};
    
    \draw [arrow] (a1) -- (a2);
    \draw [arrow] (a2) -- (a3);
    \draw [arrow] (a3) -- (a4);
    \draw [arrow] (a4) -- (a5);
    \draw [arrow] (a5.east)  -- ++(1.5,0) |- (a1.east);
    \draw [arrow] (a3.west)  -- ++(-1.5,0) |- (a5.west);
  \end{tikzpicture}
  \caption{CR life cycle\cite{Sommerville2010}.}
  \label{fig:cr-life-cycle}
\end{figure}

In this context, our goal is to indicate the best ML classifier to predict the severity level of a CR in an imbalanced data scenario, based on the assessment the accuracy of three traditional ML algorithms: Neural Networks (NN), Random Forest (RF) and Support Vector Machine(SVM). 

To systematize our evaluation, our experiments should answer the following research questions:

\begin{enumerate}[RQ 1:]
  \item \textit{Will the change request severity level change during its lifecycle?} we have investigated the accuracy of the classifiers to answering a binary response question: if CR will remain its severity level or it will change.
  \item \textit{Will the change request severity level increase, decrease or remain the same during its lifecycle}? we have investigated the accuracy of the classifiers to answering a ternary response question: if CR will remain, increase or decrease its severity level.
  \item \textit{What will the change request severity level at the end of its lifecycle?} Finally, we have investigated the accuracy of the classifiers to answering a question with more than three responses.
\end{enumerate}

This paper aims to deliver the following contributions: 

\begin{enumerate}
  \item Indicate the performance of three ML algorithms to answering questions with two, three or more responses in an imbalanced scenario.  
  \item Suggest another way to measure the performance of ML algorithms in imbalanced data scenario besides the traditional forms used for this purpose.
  \item Advance the researches on the topics discussed in this article.
\end{enumerate}

The structure of this paper is as follows. In Section 2, we describe some related works. In Section 3, we provide the information background about CR systems, text mining and machine learning techniques necessary to understand our approach. Section 4 describe our work. Findings and discussions are presented in Section 5. Finally, we conclude and discuss future work in Section 6.


\section{Related Works}

Menzies\cite{Menzies2008} have developed a method, named SEVERIS (SEVERity ISsue assessment), for evaluating the severity of changes requests. SEVERIS is based on common text mining techniques (e.g. tokenization, stop word removal, stemming, Tf*Idf and InfoGain) and on the data mining techniques (e.g. RIPPER). The method was applied to five projects managed by the Project and Issue Tracking System (PITS). - an issue tracker system used by NASA.

Lamkanfi et al.\cite{Lamkanfi2010} have developed an approach to predict severity level of a CR based on text mining algorithms (tokenization, stop word removal, stemming) and on the Naïve Bayes machine learning algorithm. They have been validated their approach over from three open source project Mozilla, Eclipse, and GNOME and they accomplished that a training set with approximately 500 change requests per severity degree are enough to predict it with a reasonable accuracy. In another following work, Lamkanfi et al.\cite{Lamkanfi2011}, these authors compared the accrual of four machine-learning algorithms (Naïve Bayes Multinomial, K-Nearest Neighbor, and Support Vector Machine). They have been concluded that Naïve Bayes Multinomial gave superior performance compared to the others proposed algorithms.

Valdivia et al.\cite{ValdiviaGarcia2014} have characterized blocking bugs in six open source projects and proposed a model to predict them. Their model was composed of 14 distinct factors or features (e.g. the textual description, location the bug is found in and the people involved with the bug). Based on these factors they build decision trees for each project to predict whether a bug will be a blocking bug or not. Then, they analyze these decision trees to determine which factors best indicate these blocking bugs. 

\section{BACKGROUND}
In this section, we describe de change request process. Next we explain the common approach to pre-processing textual documents, and lastly, we highlight the three ML algorithms: Neural Networks, Random Forest and SVM.

\subsection{Change Request Systems}
Change Request systems\cite{Pressman2009} are software employed to keep the recording and tracking information of requests for modifications, bug fixes, and support that could occur during the software life cycle. 

Although there is no a common sense regarding the terminology or the amount of information that users must fill in to complete his requisition between popular CR systems (e.g. Bugzilla, Jira, and Redmine)\cite{Tian2012}, typically, they shall fill in a form containing at least the following attributes shown in Table \ref{tab:commom_attributes_cr_form}. 

\begin{table}[!ht]
	% increase table row spacing, adjust to taste
	\renewcommand{\arraystretch}{1.3}
	\caption{Commom attributes in the CR forms.}
	\label{tab:commom_attributes_cr_form}
	\centering
	\begin{tabular}{|l|p{6cm}|}
		\hline
		Type & Type of request (e.g. bug, new feature, improvement, and new feature)\\
		\hline
		Title & Short description of request in one line.\\
		\hline
		Description & Long and detailed description of request in many lines. It could include source code snippets and stack tracing reports.\\
		\hline
		Severity & Level of severity of request (e.g. blocker, critical, major, minor and trivial).\\
		\hline 
	\end{tabular}
\end{table}

Once the request has been registered by the user, the development team will assess it and, if it not canceled for some reason (e.g. duplication), they will complement the information with, for example, the person responsible for handling this request. All these data are stored in a repository, keeping relevant historical data about a particular software.

\subsection{Text Mining}
Text mining is the process to convert unstructured text into a structure suited to analysis\cite{Feldman2007}. It is composed of three basic activities\cite{Williams2011}: tokenization, stop word removal and stemming.

Tokenization is the action to parsing a character stream into a sequence of tokens by splitting the stream at delimiters. In this context, a token is defined as a block of text or a string of characters (without delimiters such as spaces and punctuation) that is recognized as a useful portion of the unstructured data.

Stop words eliminates commonly used words that do not provide relevant information to a particular context, including prepositions, conjunctions, articles, common verbs, nouns, pronouns, adverbs, and adjectives.

Stemming is the process stemming is the process of reducing or normalizing inflected (or sometimes derived) words to their word stem, base form—generally a written word form (e.g. “working” and worked into work).

\subsection{Machine Learning}
The machine learning is considered a part of artificial intelligence area whose the primary purpose is to resolve a given problem using experience or example data\cite{Surya2016}. It can be seen as an improvement over a set of techniques or methodologies which can make a computer to learn by the study of data sets.

% TODO: colocar referências.
\subsubsection{Neural Networks}
Neural Network is a learning algorithm that is inspired by the structure and functional aspects of biological neural networks\cite{Russell2010}. Computations are structured regarding an interconnected group of artificial neurons, processing information using a connectionist approach to computation. 

Modern neural networks are non-linear statistical data modeling tools. They are usually used to model complex relationships between inputs and outputs, to find patterns in data, or to capture the statistical structure in an unknown joint probability distribution between observed variables.

\subsubsection{Random Forest}
The Random Forest algorithm\cite{Breiman2001} relies on two core principles: (i) in the creation of hundreds of decision trees and the joining them into a single model; and (ii) in the closing decision based on the ruling of the majority of the forming trees which are treated as equals.

A random forest model is considered a suited alternative for model construction for a many of reasons\cite{Williams2011} 

\begin{itemize}
  \item Requires little or no data preprocessing, no data normalization and it is resilient to outliers.
  \item Requires no variable selections because the algorithm does its own.
  \item Models resultants from each tree in the forest tend not to overfit to the training dataset because they are built using two levels of randomness (observations and variables).
\end{itemize}

\subsubsection{Support Vector Machine}
Support Vector Machine is considered the most popular algorithm for supervised learning and an excellent first method to testing\cite{Russell2010}. It is a set of related supervised learning methods used for classification and regression. Each example in a set of training data is marked as belonging to one of two categories an the SVM algorithm builds a model that predicts whether a new example falls into one category or the other. 

\subsection{Evaluation Metrics}
From Information Retrieve(IR) discipline, the three most common performance measures for evaluating the accuracy of classification algorithms are precision, recall, and F-measure\cite{Feldman2007}. 

\textbf{Recall}. The recall for a class can be defined as the percentage of correctly classified observations among all observations belonging to that class. It can be thought of as a measure of a classifiers completeness. More formally\cite{Facelli2015}: the recall is the number of True Positives(TP) divided by the number of True Positives(TP) and the number of False Negatives(FN), where the TP and FN values are derived from the confusion matrix. A low recall indicates many False Negatives\cite{Zhao2013}.

\textbf{Precision}. The precision is the percentage of correctly classified observations among all observations that were assigned to the class by the classifier. It can be thought of as a measure of classifier exactness. More formally\cite{Facelli2015}: the precision is the number of True Positives(TP) divided by the number of True Positives and False Positives(FP), as well as TP and FN, FP also comes from the confusion matrix. A low precision can also indicate a large number of False Positives\cite{Zhao2013}.

\textbf{F-measure}. F-measure conveys the balance between the precision and the recall and combines the two measures in an ad hoc way\cite{Feldman2007, Zhao2013}.F-measure can be calculated using the formula $2*((precision*recall))/(precision+recall)$. 


\section{Experiment}
In this section, we describe our approach which was conducted following the steps in Figure \ref{fig:methodology}

\begin{figure}[!ht]	
	\centering
	\begin{tikzpicture}[node distance=1.5cm]
		\node (a1) [activity] {Data Collection};
		\node (a2) [activity, below of=a1] {Preprocessing};
		\node (a3) [activity, below of=a2] {Training and Testing};
		\node (a4) [activity, below of=a3] {Results Evaluation};
		
		\draw [arrow] (a1) -- (a2);
		\draw [arrow] (a2) -- (a3);
		\draw [arrow] (a3) -- (a4);;
		%%\draw [arrow] (a4.east)  -- ++(2.5,0) |- (a1.east);
	\end{tikzpicture}
	\caption{Methodology used in this study.}
	\label{fig:methodology}
\end{figure}

\subsection{Data Collection}. 
We have created our dataset to training and testing the machine learning from the changes requests data collected from Apache HADOOP project. According to [hadoop.apache.org], HADOOP is "framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is considered a specialized and complex OSS project with many users with distinct expertise level. This fact has provided us access to change requests, in XML format, with different levels of information. From CR's long descriptions with few character lines to ones with many lines, including even code snippets and exception stack trace.

The users of HADOOP have registered and stored their CRs via Jira
software[\url{https://www.atlassian.com/software/jira}]. To collect these data, we have organized its extraction into two steps: (i) the copying of CR basic data (e.g. status and resolution) in XML; and (ii) the copying of CR changes histories in HTML, both from HADOOP web site[\url{http://issues.apache.org}]. About 10\% of the CRs collected in this process changed at least once their level of severity.

We collected CR published from February 01, 2006 to January 18, 2017.  We only retrieved requests from the common module which identifier started with HADOOP. The total number of records retrieved after preprocessing was 7129 change requests. Figure \ref{fig:ds_distribution} shows three charts with requests distribution by severity level and severity level changes.

\begin{figure*}[!hbt]
  \label{fig:ds_distribution}
  \includegraphics{figures/ds_distribution.pdf}
  \caption{Dataset distribution by severity level.}
\end{figure*}


The graph (a) shows that of 7129 change requests, 3.6\% had severity 1(trivial); 16.8\% had severity 2(minor); 62.2\% had severity 3(major), 4.0\% had severity 4(critical), And 13.4\% had severity 5(blocker). The graph (b) shows that 91.9\% of them haven't changed their severities levels and 8.1\% have changed. And the graph (c) reveals that of the 8.1\% which changed their severity, 23.3\% decreased it, and 76.7\% increased it. We can note that dataset is clearly imbalanced.


\subsection{Preprocessing}
The CR data stored in XML and HTML files which we have copied from HADOOP website weren't in tidy data\cite{DeJonge2013}, i.e., it wasn't in appropriated format to train and test the machine learning. To convert it to this suitable format, we have coded and run scripts written in language R. These scripts execute the following tasks:
\begin{itemize}
 \item Extraction from files many features: the key, the type, the status, the resolution and the long description of CR's;
 \item Filtering the only CR's with status equals to Closed and resolution equals to Fixed and Implemented. 
 \item Merging the CR's features with history data to discover what CR's have changed its severity level and if there was increasing or decreasing in this level.
 \item Extraction from the long description initially the one hundred the most frequent words and convert them into features for each CR.
 \item Classifying the CR's in ascending chronological date. 
\end{itemize}


\subsection{Training and testing}. 

To train and test de machine learning, we have partitioned the dataset generated after preprocessing in two distinct pieces: one part for training with 60\% of the dataset and one part for testing with 40\% of the dataset. In the training phase, we have used the 3-fold cross-validation technique to choose the best values for hyperparameters for each classifier algorithm to use them in the test phase. 

\section{Findings and Discussions}

\subsection{RQ1: Will the change request severity level change during its lifecycle?}

The RQ1 is a simple binary problem, i.e., a question whose answer is true or false. The Table \ref{tab:metrics_for_rq1} shows the performance (in percentage) of the classifiers to predict the response to this issue.

% 0.9179235
\begin{table}[!ht]
	\renewcommand{\arraystretch}{1.3}
	\caption{Classifiers Performances on RQ1.}
	\label{tab:metrics_for_rq1}
	\centering
	\begin{tabular}{|l|c|c|c|}
		\hline
		Classifier & Precision & Recall & F-Measurement\\
		\hline 
		NN & 93,381 & 98,015 & 95,642\\
		\hline
		RF & 93,801 & 99,923 & 96,765\\
        \hline
		SVM & 93,727 & 99,809 & 96,627 \\
		\hline
		
	\end{tabular}
\end{table}

We tested the classifiers with 2851(40\% of 7129) change requests: 2620 have changed their severity level, and 231 haven't changed their severity level. We can observe that the three classifiers performed very closely. However, the Random Forest classifier have achieved a F1-Measure somewhat better than the two others.

Regarding the Random Forest classifier we have done one step further, we have investigated its performance relating to the number of hits and errors made in answer to RQ1. The Figure \ref{fig:rf_performance_for_q1} indicates that its accuracy was 93.681\% (2676 divide by 2851). 

\begin{figure}[!hbt]
  \label{fig:rf_performance_for_q1}
  \includegraphics[width=0.5\textwidth, height=0.42\textwidth]{figures/rf_performance_for_q1.pdf}
  \caption{Performance of Random Forest for RQ1.}
\end{figure}

\subsection{RQ2: Will the change request severity level increase, decrease or remain the same during its lifecycle}

The RQ2 poses a problem more difficult than a previous question. It is a question with three possible responses related to severity level: (-1) it has decreased; (0)  it has remained; and (1) it has increased. The Table \ref{tab:metrics_for_rq2} shows the performance (in percentage) of the classifiers to predict the response to this issue.

\begin{table}[!ht]
	% increase table row spacing, adjust to taste
	\renewcommand{\arraystretch}{1.3}
	\caption{Classifiers Performance on RQ2.}
	\label{tab:metrics_for_rq2}
	\centering
	\begin{tabular}{l|c|c|c|c|}
		\cline{2-5}
		& Class & Precision & Recall & F-Measurement\\
		\hline\cline{2-5}
        \multicolumn{1}{ |c| }{\multirow{4}{*}{\rotatebox[origin=c]{90}{\small{NN}}}} & -1 & 3.703 & 28.571 & 6.557\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 0 & 97.663 & 93.357 & 95.447\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 1 & 22.598 & 38.461 & 28.469\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & Average & 41.311 & 53.463 & 43.491 \\
		\hline\hline 
		\multicolumn{1}{ |c| }{\multirow{4}{*}{\rotatebox[origin=c]{90}{\small{RF}}}} & -1 & 13.111 & 85.714 & 19.672\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 0 & 99.923 & 93.500 & 96.605\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 1 & 28.598 & 90.652 & 46.199\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & Average & 47.210 & 89.955 & 54.158 \\

		\hline\hline 
		\multicolumn{1}{ |c| }{\multirow{4}{*}{\rotatebox[origin=c]{90}{\small{SVM}}}} 		
		& -1 & 12,962 & 70,000 & 21,875\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 0 & 99,923 & 93,902 & 96,819\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 1 & 27,118 & 90,566 & 41,739\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & Average & 46,667 & 84,822 & 53,477 \\
		
		
		\hline
		 
	\end{tabular}
\end{table}


We have tested the classifiers with 2851(40\% of 7129) change requests. Only now, we have three predicting situations: 2620 haven't changed their severity level, 177 have increased their severity level, and 54 have decreased their severity level. We can observe in the Table \ref{tab:metrics_for_rq2} which the classifiers also performed very closely as question 1. However, the Random Forest classifier have achieved F-Measure somewhat better than the two others.

Like as in the RQ1, we have done one step further regarding the best classifier, we have investigated its performance, observing the number of correct and incorrect answers on the test dataset as a whole. The Figure \ref{fig:rf_performance_for_q2} indicates that its accuracy was 93.440\% (2664 divide by 2851) in the RQ2 prediction. 

\begin{figure}[!hbt]
   \label{fig:rf_performance_for_q2}
  \includegraphics[width=0.5\textwidth, height=0.42\textwidth]{figures/rf_performance_for_q2.pdf}
  \caption{Performance of Random Forest for RQ2.}
\end{figure}

\subsection{RQ3: Is it possible to predict the change request severity level at the end of its lifecycle?}

The RQ3 is a problem much harder than other two. It is a question with five responses related to severity level: (1) trivial; (2) minor; (3) major; (4) critical; and (5) blocker. The Table \ref{tab:metrics_for_rq3} shows the performance (in percentage) of the classifiers to predict the response to this issue.


\begin{table}[!ht]
	% increase table row spacing, adjust to taste
	\renewcommand{\arraystretch}{1.3}
	\caption{Classifiers Performance on RQ3.}
	\label{tab:metrics_for_rq3}
	\centering
	\begin{tabular}{l|c|c|c|c|}
		\cline{2-5}
		& Class & Precision & Recall & F-Measurement\\
		\hline\cline{2-5}
        \multicolumn{1}{ |c| }{\multirow{4}{*}{\rotatebox[origin=c]{90}{\small{NN}}}} & 1 & 4.950 & 29.411 & 8.474\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 2 & 18.997 & 34.469 & 24.495\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 3 & 88.726 & 66.273 & 75.873\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & 4 & 16.964 & 37.254 & 23.312\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & 5 & 17.015 & 46.099 & 24.856\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & Average & 29.330 & 39.606 & 31.402 \\
		\hline\hline 
		\multicolumn{1}{ |c| }{\multirow{4}{*}{\rotatebox[origin=c]{90}{\small{RF}}}} & 1 & 4.950 & 83.333 & 9.345\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 2 & 16.283 & 76.470 & 26.850\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 3 & 98.308 & 67.387 & 79.963\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & 4 & 30.357 & 100.000 & 46.575\\
		\cline{2-5} 
	    \multicolumn{1}{ |c| }{} & 5 & 25.130 & 81.355 & 38.400\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & Average & 35.005 & 81.709 & 40.226 \\
		\hline\hline 
		\multicolumn{1}{ |c| }{\multirow{4}{*}{\rotatebox[origin=c]{90}{\small{SVM}}}} & 1 & 6.930 & 70,000 & 12.612\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 2 & 16.283 & 77.227 & 26.896\\
		\cline{2-5}
		\multicolumn{1}{ |c| }{} & 3 & 95.478 & 67.166 & 78.857\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & 4 & 30.357 & 97.142 & 46.258\\
		\cline{2-5} 
	    \multicolumn{1}{ |c| }{} & 5 & 23.036 & 87.128 & 36.438\\
		\cline{2-5} 
		\multicolumn{1}{ |c| }{} & Average & 34.416 & 79.7326 & 40.212 \\
		\hline
		 
	\end{tabular}
\end{table}


We have tested the classifiers with 2851(40\% of 7129) change requests. Only now, we have six predicting situations: 101 are trivial; 479 are minor; 1774 are major; 112 are critical; 382 are a blocker. We can observe in the Table \ref{tab:metrics_for_rq2} which the classifiers also performed very closely as questions 1 and 2. However, the Random Forest classifier have achieved a F1-Measure somewhat better than the two others.


Like as in the RQ1 and RQ2, we have done one step further regarding the best classifier, we have investigated its performance, observing the number of correct and incorrect answers on the test dataset as a whole. The Figure \ref{fig:rf_performance_for_q3} shows three graphs. The graph (a) shows user range error in the assignment of severity level. The graph (b) shows the classifier error in the assignment of severity level. And the graph (c) compares de Predictor Error (PE) with User Error(UE) in terms of the amount of change requests whose predictions. We can note that the random forest performance was also 68,08\% (1941 divide by 2851). 


\begin{figure*}[ht]
  \label{fig:rf_performance_for_q3}
  \includegraphics{figures/rf_performance_for_q3.pdf}
  \caption{Performance of Random Forest for RQ3.}
\end{figure*}


Although we can consider that accuracy a good value, the graph (a) shows that user accuracy was 91.18\% and graph (c) also shows that 745 change requests, the PE was greater than UE. From a business vision, the predictor have not show suitable performance.

\section{Threats to Validity}
Runeson \cite{Runeson2009} recommends that threats to validity should be considered under four aspects: construct validity;  internal validity; external validity; and reliability.

\textbf{Construct validity}. Despite existing others metrics to evaluate classifiers\cite{Facelli2015}, which could be more suitable than precision, recall and F1-measure, we prefer to use them because they have been used satisfactorily in related works\cite{Menzies2008, Lamkanfi2010, Lamkanfi2011, ValdiviaGarcia2014}.


\textbf{Internal validity}. We assume that level of severity assignment by the user is correct and that there is an intimate relationship between it and the long description of the change request. This assumption finds echo or support in \cite{Lamkanfi2010, Tian2012}

\textbf{External validity}. We have considered one single repository and we have extracted 8858 change requests from it. Although we can't generalize the results to others, the characteristics presented by HADOOP repository, particularly regarding the balance of the data, are similars to those shown in the repositories studied\cite{Lamkanfi2010, Lamkanfi2011, Tian2012,ValdiviaGarcia2014}.

\textbf{Reliability}. The code developed in the Java language and the R language for preprocessing, training, testing and analysis of results have been carefully checked may contain bugs. To minimize this problem, we rely heavily on libraries offered by them such as XStream (the XML parser), nnet (a neural network R implementation), randomForest (a random forest R implementation) and e1071 (a SVM R implentation). 

\section{Conclusion and Future Work}
In this paper, we assess the Neural Network, Random Forest and Support Vector Machine, three popular ML algorithms to CR severity level in imbalanced data scenario. We have considered the CR long description as the main factor to
this prediction. The features of machine learning were derived from
words(token) from this description. The results on a dataset consisting more than
8,000 CR from Hadoop have shown that random forest performed well to predict the severity level will change and whether severity will increase or decrease with reasonable accuracy, around 93.681\% and 93.440\% respectively. However, it has provided the accuracy (around 68,08\%) to predict the final last severity level on imbalanced data scenario.

\section*{Acknowledgment}
This work has been carried out in the context of Ph.D program of  Computing Institute at State University of Campinas (UNICAMP), Brazil). Additional sponsoring by Permanent Professor Preparation Program(PPP) of Pontifical Catholic University of Minas Gerais (PUC MG). 


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{references}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}
%\bibliographystyle{IEEEtran}

%\end{thebibliography}




% that's all folks
\end{document}


